{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Name**: Teo Choun Meng\n",
        "\n",
        "**UOW ID**: 7919591\n"
      ],
      "metadata": {
        "id": "agvuRQIVkwxg"
      },
      "id": "agvuRQIVkwxg"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Instructions:\n",
        "\n",
        " 1. Understand the code and execute the instructions in each cell. If there is no evidence of code execution, NO marks will be awarded.\n",
        " 2. Answer the following questions using the corresponding Markdown cells.\n",
        " 3. Submission:\n",
        " * Export to PDF: File → Print → Save as PDF (entire notebook).\n",
        " * Filename: Lab1_UOWID.pdf\n",
        " * Deadline: 26 Oct 2025, 11:55 pm (2 attempts max).\n",
        "\n"
      ],
      "metadata": {
        "id": "el4I2Ig9pfR4"
      },
      "id": "el4I2Ig9pfR4"
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q1**. Describe how the input image is handled differently in the DNN versus the CNN in the notebook. Explain why such differences exist. (2 marks)\n",
        "\n",
        "**Ans**:\n"
      ],
      "metadata": {
        "id": "aaadQUQLk-fh"
      },
      "id": "aaadQUQLk-fh"
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q2**. Explain what happens in each step of the training loop for CNN vs DNN model. Screen capture the relevant code in the notebook to support your answers(3 marks).\n",
        "\n",
        "**Ans**:"
      ],
      "metadata": {
        "id": "D1-_jdRJlOBQ"
      },
      "id": "D1-_jdRJlOBQ"
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q3**. Comment on the performance of CNN vs DNN.  Relate your observations to the theory covered in Lecture 2 and/or Tutorial 1. (3 marks).\n",
        "\n",
        "**Ans**:"
      ],
      "metadata": {
        "id": "BIL9yy6SlwNC"
      },
      "id": "BIL9yy6SlwNC"
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q4**. Report how loss changes across epochs for both CNN and DNN. Relate the loss figures to how well the models are learning. Screen capture the relevant execution results to support your answers.(2 marks).\n",
        "\n",
        "**Ans**:\n",
        "\n"
      ],
      "metadata": {
        "id": "wybfiPznnBGs"
      },
      "id": "wybfiPznnBGs"
    },
    {
      "cell_type": "markdown",
      "id": "e81c3d2b",
      "metadata": {
        "id": "e81c3d2b"
      },
      "source": [
        "\n",
        "# CSCI323 Lab 1: CIFAR-10: CNN vs DNN\n",
        "\n",
        "This notebook loads CIFAR-10 and trains **two models** on the same data:\n",
        "\n",
        "- **CNN** (2×Conv→Pool + 3×FC) — similar to the PyTorch tutorial\n",
        "- **DNN** (3×Fully Connected) — images flattened to vectors\n",
        "\n",
        "It logs metrics and plots **overlay charts** for training vs validation curves per model.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c08c412a",
      "metadata": {
        "id": "c08c412a"
      },
      "outputs": [],
      "source": [
        "\n",
        "#@title (Optional) Install/upgrade libraries\n",
        "# On standard Colab this is typically not needed.\n",
        "# !pip install -q torch torchvision torchaudio\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "acfe488f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "acfe488f",
        "outputId": "9918a83a-f949-4cbf-8540-bd714a6c9a38"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cpu')"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "device\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5dc5a7df",
      "metadata": {
        "id": "5dc5a7df"
      },
      "source": [
        "## Data: CIFAR-10 loaders (train/test with normalization)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "90511a97",
      "metadata": {
        "id": "90511a97"
      },
      "outputs": [],
      "source": [
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
        "])\n",
        "\n",
        "batch_size = 128\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "testset  = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
        "\n",
        "trainloader = DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=2, pin_memory=True)\n",
        "testloader  = DataLoader(testset,  batch_size=batch_size, shuffle=False, num_workers=2, pin_memory=True)\n",
        "\n",
        "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
        "len(trainset), len(testset), classes\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3c7ae9a1",
      "metadata": {
        "id": "3c7ae9a1"
      },
      "source": [
        "## Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c168e972",
      "metadata": {
        "id": "c168e972"
      },
      "outputs": [],
      "source": [
        "\n",
        "class SmallCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 6, 5)   # -> 6x28x28\n",
        "        self.pool  = nn.MaxPool2d(2, 2)   # -> 6x14x14\n",
        "        self.conv2 = nn.Conv2d(6, 16, 5)  # -> 16x10x10 -> pool -> 16x5x5\n",
        "        self.fc1   = nn.Linear(16*5*5, 120)\n",
        "        self.fc2   = nn.Linear(120, 84)\n",
        "        self.fc3   = nn.Linear(84, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class SimpleDNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.fc1 = nn.Linear(32*32*3, 512)\n",
        "        self.fc2 = nn.Linear(512, 256)\n",
        "        self.fc3 = nn.Linear(256, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "47534c86",
      "metadata": {
        "id": "47534c86"
      },
      "source": [
        "## Training & Evaluation Utilities"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "15ae5df1",
      "metadata": {
        "id": "15ae5df1"
      },
      "outputs": [],
      "source": [
        "\n",
        "def train_one_epoch(model, loader, criterion, optimizer, device):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    for inputs, labels in loader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item() * inputs.size(0)\n",
        "        _, predicted = outputs.max(1)\n",
        "        total += labels.size(0)\n",
        "        correct += predicted.eq(labels).sum().item()\n",
        "\n",
        "    avg_loss = running_loss / total\n",
        "    acc = correct / total\n",
        "    return avg_loss, acc\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def evaluate(model, loader, criterion, device):\n",
        "    model.eval()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    for inputs, labels in loader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        running_loss += loss.item() * inputs.size(0)\n",
        "        _, predicted = outputs.max(1)\n",
        "        total += labels.size(0)\n",
        "        correct += predicted.eq(labels).sum().item()\n",
        "\n",
        "    avg_loss = running_loss / total\n",
        "    acc = correct / total\n",
        "    return avg_loss, acc\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def per_class_accuracy(model, loader, classes, device):\n",
        "    model.eval()\n",
        "    correct = {c: 0 for c in classes}\n",
        "    total = {c: 0 for c in classes}\n",
        "\n",
        "    for inputs, labels in loader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        outputs = model(inputs)\n",
        "        _, pred = outputs.max(1)\n",
        "        for y, p in zip(labels, pred):\n",
        "            total[classes[y]] += 1\n",
        "            if y == p:\n",
        "                correct[classes[y]] += 1\n",
        "\n",
        "    return {c: (correct[c] / total[c]) if total[c] > 0 else 0.0 for c in classes}\n",
        "\n",
        "\n",
        "def plot_curve(values, title, ylabel):\n",
        "    plt.figure()\n",
        "    plt.plot(values)\n",
        "    plt.title(title)\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel(ylabel)\n",
        "    plt.grid(True)\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def plot_overlay(train_values, val_values, title, ylabel):\n",
        "    plt.figure()\n",
        "    plt.plot(train_values, label='Train')\n",
        "    plt.plot(val_values, label='Validation')\n",
        "    plt.title(title)\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel(ylabel)\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a76a1d08",
      "metadata": {
        "id": "a76a1d08"
      },
      "source": [
        "## Train Both Models (adjust epochs/hparams below)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cbcf1adc",
      "metadata": {
        "id": "cbcf1adc"
      },
      "outputs": [],
      "source": [
        "\n",
        "epochs_cnn = 10  # feel free to edit\n",
        "epochs_dnn = 20  # DNN often needs more epochs\n",
        "lr_cnn = 0.001\n",
        "lr_dnn = 0.001\n",
        "\n",
        "cnn = SmallCNN().to(device)\n",
        "dnn = SimpleDNN().to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "opt_cnn = optim.Adam(cnn.parameters(), lr=lr_cnn)\n",
        "opt_dnn = optim.Adam(dnn.parameters(), lr=lr_dnn)\n",
        "\n",
        "history = {\n",
        "    'cnn_train_loss': [], 'cnn_train_acc': [],\n",
        "    'cnn_val_loss': [],   'cnn_val_acc':  [],\n",
        "    'dnn_train_loss': [], 'dnn_train_acc': [],\n",
        "    'dnn_val_loss': [],   'dnn_val_acc':  [],\n",
        "}\n",
        "\n",
        "print('Training CNN...')\n",
        "for epoch in range(epochs_cnn):\n",
        "    tl, ta = train_one_epoch(cnn, trainloader, criterion, opt_cnn, device)\n",
        "    vl, va = evaluate(cnn, testloader, criterion, device)\n",
        "    history['cnn_train_loss'].append(tl)\n",
        "    history['cnn_train_acc'].append(ta)\n",
        "    history['cnn_val_loss'].append(vl)\n",
        "    history['cnn_val_acc'].append(va)\n",
        "    print(f'[CNN] Epoch {epoch+1}/{epochs_cnn}: train_loss={tl:.4f} acc={ta:.3f} | val_loss={vl:.4f} acc={va:.3f}')\n",
        "\n",
        "print('\\nTraining DNN...')\n",
        "for epoch in range(epochs_dnn):\n",
        "    tl, ta = train_one_epoch(dnn, trainloader, criterion, opt_dnn, device)\n",
        "    vl, va = evaluate(dnn, testloader, criterion, device)\n",
        "    history['dnn_train_loss'].append(tl)\n",
        "    history['dnn_train_acc'].append(ta)\n",
        "    history['dnn_val_loss'].append(vl)\n",
        "    history['dnn_val_acc'].append(va)\n",
        "    print(f'[DNN] Epoch {epoch+1}/{epochs_dnn}: train_loss={tl:.4f} acc={ta:.3f} | val_loss={vl:.4f} acc={va:.3f}')\n",
        "\n",
        "print('Done.')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d1bb5387",
      "metadata": {
        "id": "d1bb5387"
      },
      "source": [
        "## Overlayed Curves: Training vs Validation (per model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "31b35687",
      "metadata": {
        "id": "31b35687"
      },
      "outputs": [],
      "source": [
        "\n",
        "# CNN overlays\n",
        "plot_overlay(history['cnn_train_loss'], history['cnn_val_loss'], 'CNN Loss (Train vs Validation)', 'Loss')\n",
        "plot_overlay(history['cnn_train_acc'],  history['cnn_val_acc'],  'CNN Accuracy (Train vs Validation)', 'Accuracy')\n",
        "\n",
        "# DNN overlays\n",
        "plot_overlay(history['dnn_train_loss'], history['dnn_val_loss'], 'DNN Loss (Train vs Validation)', 'Loss')\n",
        "plot_overlay(history['dnn_train_acc'],  history['dnn_val_acc'],  'DNN Accuracy (Train vs Validation)', 'Accuracy')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0c729079",
      "metadata": {
        "id": "0c729079"
      },
      "source": [
        "## Per-Class Accuracy (optional)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "85ab29d7",
      "metadata": {
        "id": "85ab29d7"
      },
      "outputs": [],
      "source": [
        "\n",
        "cnn_cls = per_class_accuracy(cnn, testloader, classes, device)\n",
        "dnn_cls = per_class_accuracy(dnn, testloader, classes, device)\n",
        "\n",
        "print('Per-class accuracy — CNN')\n",
        "for c in classes:\n",
        "    print(f'{c:>6s}: {cnn_cls[c]*100:.1f}%')\n",
        "\n",
        "print('\\nPer-class accuracy — DNN')\n",
        "for c in classes:\n",
        "    print(f'{c:>6s}: {dnn_cls[c]*100:.1f}%')\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}